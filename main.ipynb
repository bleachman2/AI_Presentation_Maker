{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Point Presentation maker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    msg = \"Missing API_KEY\"\n",
    "    raise OSError(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pydantic class as OpenAI's expected response format\n",
    "\n",
    "[OpenAI docs - structured format](https://platform.openai.com/docs/guides/structured-outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SingleSlide(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "    visual: str\n",
    "\n",
    "\n",
    "class ResponseFormat(BaseModel):\n",
    "    slide: list[SingleSlide]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompts import sys_prompt, usr_prompt\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": sys_prompt},\n",
    "        {\"role\": \"user\", \"content\": usr_prompt},\n",
    "    ],\n",
    "    response_format=ResponseFormat,\n",
    ")\n",
    "event = completion.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Day-to-Day AI Tools for Developers\n",
      "An overview of essential AI tools that can enhance productivity and efficiency in development tasks.\n",
      "image of diverse AI tools\n",
      "\n",
      "Introduction to AI Tools for Developers\n",
      "The rapid evolution of AI technology has provided developers with a plethora of tools to streamline workflows, troubleshoot coding issues, and enhance overall project outcomes. This presentation will discuss some of the most useful AI tools available today and how they can be integrated into your daily coding practices.\n",
      "introductory graphic of AI technology\n",
      "\n",
      "Search Tools: Perplexity\n",
      "Perplexity is an advanced search tool that leverages AI to provide relevant search results quickly. Ideal for developers looking for quick answers and references during coding.\n",
      "screenshot of Perplexity interface\n",
      "\n",
      "Research Tools: NotebookLM\n",
      "NotebookLM helps developers organize research and collaborate on notes seamlessly. It integrates coding environments with documentation, making it easier to access vital information.\n",
      "image of NotebookLM features\n",
      "\n",
      "Transcription Tool: Otter.ai\n",
      "Otter.ai transforms audio notes into written documentation. Developers can use it to transcribe meetings or brainstorming sessions, enhancing team communication and record-keeping.\n",
      "screenshot showing Otter.ai transcription process\n",
      "\n",
      "Manual Coding LLM Integration\n",
      "Implementing Language Learning Models (LLMs) into your manual coding processes can boost efficiency. This slide provides a step-by-step approach to effectively integrate LLMs into your applications.\n",
      "diagram of LLM integration process\n",
      "\n",
      "Summary of AI Tools for Developers\n",
      "This section summarizes the AI tools discussed, highlighting their unique features and potential benefits in the development cycle.\n",
      "bullet points listing tools with icons\n",
      "\n",
      "Q & A Session\n",
      "Open the floor for questions regarding the tools presented, their integration, and experiences with AI technologies in coding.\n",
      "image inviting questions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in event.slide:\n",
    "    print(f\"{i.title}\\n{i.content}\\n{i.visual}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to create images with Stable Diffusion\n",
    "\n",
    "Using a local Stable Diffusion API to create the images, currently WebUI Forge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "# Define the URL and the payload to send.\n",
    "url = \"http://127.0.0.1:7860\"\n",
    "\n",
    "\n",
    "def imagecreator(prompt: str, name: str, width: int, height: int) -> None:\n",
    "    \"\"\"Access local Stable Diffusion to create images.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): prompt for image creation\n",
    "        name (str): Name of the resulting image\n",
    "        width (int): Image Width\n",
    "        height (int): Image Height\n",
    "\n",
    "    \"\"\"\n",
    "    payload = {\n",
    "        \"prompt\": prompt,\n",
    "        \"steps\": 20,\n",
    "        \"sampler_name\": \"DPM++ 2M\",\n",
    "        \"scheduler\": \"Beta\",\n",
    "        \"cfg_scale\": 1,\n",
    "        \"width\": width,\n",
    "        \"height\": height,\n",
    "    }\n",
    "\n",
    "    # Send said payload to said URL through the API.\n",
    "    response = requests.post(url=f\"{url}/sdapi/v1/txt2img\", json=payload, timeout= 300)\n",
    "    r = response.json()\n",
    "\n",
    "    # Decode and save the image.\n",
    "    with Path(f\"images/{name}.png\").open(\"wb\") as f:\n",
    "        f.write(base64.b64decode(r[\"images\"][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a PPTX with the responses generated with ChatGPT and the Stable Diffusion images\n",
    "\n",
    "Using [Python-pptx](https://python-pptx.readthedocs.io/en/latest/index.html) for PowerPoint creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches\n",
    "\n",
    "prs = Presentation()\n",
    "bullet_slide_layout = prs.slide_layouts[1]\n",
    "\n",
    "for i in event.slide:\n",
    "    slide = prs.slides.add_slide(bullet_slide_layout)\n",
    "    shapes = slide.shapes\n",
    "\n",
    "    # Add background image\n",
    "    left = top = Inches(0)\n",
    "    slide_width = prs.slide_width\n",
    "    slide_height = prs.slide_height\n",
    "\n",
    "    imagecreator(i.visual + \"NO TEXT\", i.title, 955, 537)\n",
    "    pic = slide.shapes.add_picture(\n",
    "        str(Path(f\"images/{i.title}.png\")), left, top, slide_width, slide_height,\n",
    "    )\n",
    "\n",
    "    # Add Text\n",
    "    title_shape = shapes.title\n",
    "    body_shape = shapes.placeholders[1]\n",
    "\n",
    "    title_shape.text = i.title\n",
    "\n",
    "    tf = body_shape.text_frame\n",
    "    tf.text = i.content\n",
    "\n",
    "\n",
    "prs.save(\"test.pptx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
